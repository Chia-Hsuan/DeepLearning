{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "GphnZeKw-5cj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "6200d16c-7886-400d-e326-2c72522af8c2"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import cv2\n",
        "import keras\n",
        "from string import printable\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten\n",
        "from keras.models import Model, Sequential\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras import backend as K\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
        "from keras.optimizers import SGD, RMSprop\n",
        "from keras.utils import np_utils\n",
        "from keras.regularizers import l2\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from PIL import Image\n",
        "from keras.applications import VGG16\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.optimizers import RMSprop\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import callbacks\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Aj9kFGnbX4G4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1 Autoencoder"
      ]
    },
    {
      "metadata": {
        "id": "yZsmHtXV_Axk",
        "colab_type": "code",
        "outputId": "531034bb-d429-4f52-c25f-1ce38d4e553c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], 28, 28, 1))\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "print (x_train.shape)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "epMS4PP8_W6g",
        "colab_type": "code",
        "outputId": "460a0a01-7b3f-4357-f851-c7e845e97e88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        }
      },
      "cell_type": "code",
      "source": [
        "img = Input(shape=(28, 28, 1))\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoding = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoding)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoding = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(img, decoding)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "autoencoder.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_85 (Conv2D)           (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_86 (Conv2D)           (None, 14, 14, 8)         1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_38 (MaxPooling (None, 7, 7, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_87 (Conv2D)           (None, 7, 7, 8)           584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_39 (MaxPooling (None, 4, 4, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_88 (Conv2D)           (None, 4, 4, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_37 (UpSampling (None, 8, 8, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_89 (Conv2D)           (None, 8, 8, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_38 (UpSampling (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_90 (Conv2D)           (None, 16, 16, 16)        1168      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_39 (UpSampling (None, 32, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_91 (Conv2D)           (None, 32, 32, 1)         145       \n",
            "=================================================================\n",
            "Total params: 4,385\n",
            "Trainable params: 4,385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IizPYbnZ_hR7",
        "colab_type": "code",
        "outputId": "9893d069-2210-49e4-b1b2-66294a4afc4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        }
      },
      "cell_type": "code",
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=20,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 285s 5ms/step - loss: 0.3111 - val_loss: 0.3274\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 287s 5ms/step - loss: 0.2918 - val_loss: 0.2992\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 287s 5ms/step - loss: 0.2863 - val_loss: 0.2947\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 285s 5ms/step - loss: 0.2830 - val_loss: 0.2876\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 285s 5ms/step - loss: 0.2807 - val_loss: 0.2797\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 285s 5ms/step - loss: 0.2788 - val_loss: 0.2794\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 285s 5ms/step - loss: 0.2774 - val_loss: 0.2784\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 285s 5ms/step - loss: 0.2763 - val_loss: 0.2783\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 285s 5ms/step - loss: 0.2754 - val_loss: 0.2771\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 287s 5ms/step - loss: 0.2744 - val_loss: 0.2755\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 286s 5ms/step - loss: 0.2737 - val_loss: 0.2749\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 285s 5ms/step - loss: 0.2730 - val_loss: 0.2767\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 286s 5ms/step - loss: 0.2725 - val_loss: 0.2758\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 286s 5ms/step - loss: 0.2720 - val_loss: 0.2747\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 285s 5ms/step - loss: 0.2715 - val_loss: 0.2760\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 287s 5ms/step - loss: 0.2711 - val_loss: 0.2731\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 287s 5ms/step - loss: 0.2708 - val_loss: 0.2725\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 286s 5ms/step - loss: 0.2703 - val_loss: 0.2720\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 286s 5ms/step - loss: 0.2701 - val_loss: 0.2741\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 286s 5ms/step - loss: 0.2697 - val_loss: 0.2710\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f67b6ac5cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "6axEtkyy_mGg",
        "colab_type": "code",
        "outputId": "b1bb1159-0c8e-4433-9f17-0c168e10af6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "cell_type": "code",
      "source": [
        "decoded_img = autoencoder.predict(x_test)\n",
        "plt.figure()\n",
        "for i in range(5):\n",
        "    ax = plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(x_test[-i].reshape(28, 28))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    ax = plt.subplot(2, 5, i+6)\n",
        "    plt.imshow(decoded_img[-i].reshape(28, 28))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAD+CAYAAAC3HjWUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMGECAABUwIQJAABQwf8D+oPbCk/mHsgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f67b68ba828>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "NSBoR6auI0Fa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2.1 Deep CNN"
      ]
    },
    {
      "metadata": {
        "id": "NQ2m_liaCey7",
        "colab_type": "code",
        "outputId": "1ca16aee-719d-48bc-d253-44fd57a3f1a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        }
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1).astype('float32') / 255\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1).astype('float32') / 255\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 32,kernel_size=(3, 3), activation='relu', strides=(1, 1), padding='valid', input_shape=(28,28,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(filters = 64,kernel_size=(3, 3), activation='relu', strides=(1, 1), padding='valid', input_shape=(28,28,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 256)               409856    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 431,242\n",
            "Trainable params: 431,242\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ac8jfDNp4zMp",
        "colab_type": "code",
        "outputId": "2231b695-f880-49eb-dd07-38fa9ebf219e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 73s 1ms/step - loss: 0.2854 - acc: 0.8944 - val_loss: 0.2576 - val_acc: 0.9037\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 72s 1ms/step - loss: 0.2802 - acc: 0.8975 - val_loss: 0.2576 - val_acc: 0.9033\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 72s 1ms/step - loss: 0.2718 - acc: 0.8999 - val_loss: 0.2517 - val_acc: 0.9039\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 73s 1ms/step - loss: 0.2673 - acc: 0.9014 - val_loss: 0.2495 - val_acc: 0.9076\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 72s 1ms/step - loss: 0.2591 - acc: 0.9036 - val_loss: 0.2466 - val_acc: 0.9084\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 73s 1ms/step - loss: 0.2581 - acc: 0.9034 - val_loss: 0.2417 - val_acc: 0.9113\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 72s 1ms/step - loss: 0.2575 - acc: 0.9050 - val_loss: 0.2396 - val_acc: 0.9112\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 73s 1ms/step - loss: 0.2519 - acc: 0.9075 - val_loss: 0.2416 - val_acc: 0.9110\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 73s 1ms/step - loss: 0.2487 - acc: 0.9071 - val_loss: 0.2368 - val_acc: 0.9121\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 73s 1ms/step - loss: 0.2442 - acc: 0.9084 - val_loss: 0.2381 - val_acc: 0.9131\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 73s 1ms/step - loss: 0.2404 - acc: 0.9108 - val_loss: 0.2316 - val_acc: 0.9134\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 72s 1ms/step - loss: 0.2397 - acc: 0.9108 - val_loss: 0.2390 - val_acc: 0.9130\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 72s 1ms/step - loss: 0.2345 - acc: 0.9126 - val_loss: 0.2333 - val_acc: 0.9152\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 73s 1ms/step - loss: 0.2317 - acc: 0.9130 - val_loss: 0.2295 - val_acc: 0.9154\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 72s 1ms/step - loss: 0.2326 - acc: 0.9125 - val_loss: 0.2377 - val_acc: 0.9121\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 73s 1ms/step - loss: 0.2273 - acc: 0.9151 - val_loss: 0.2312 - val_acc: 0.9146\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 72s 1ms/step - loss: 0.2251 - acc: 0.9166 - val_loss: 0.2278 - val_acc: 0.9179\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 73s 1ms/step - loss: 0.2252 - acc: 0.9149 - val_loss: 0.2277 - val_acc: 0.9161\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 72s 1ms/step - loss: 0.2207 - acc: 0.9169 - val_loss: 0.2299 - val_acc: 0.9151\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 71s 1ms/step - loss: 0.2233 - acc: 0.9162 - val_loss: 0.2251 - val_acc: 0.9164\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce6ef701d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "ewFoq7HKuyNB",
        "colab_type": "code",
        "outputId": "b6c8ffe5-7867-45c9-8b34-ec42f6cab37f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Train classification accuracy rate %0.05f\" % model.evaluate(X_train, Y_train)[1])\n",
        "print(\"Test classification accuracy rate %0.05f\" % model.evaluate(X_test, Y_test)[1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 23s 383us/step\n",
            "Train classification accuracy rate 0.94877\n",
            "10000/10000 [==============================] - 4s 385us/step\n",
            "Test classification accuracy rate 0.91640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7YB1Gx1XXCiZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2.2 Transfer Learning"
      ]
    },
    {
      "metadata": {
        "id": "HjmJdgOC5Edu",
        "colab_type": "code",
        "outputId": "9850176b-2801-446d-aeeb-1cfa0327ca3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "X_train = [cv2.cvtColor(cv2.resize(i, (48,48)), cv2.COLOR_GRAY2BGR) for i in X_train]\n",
        "X_test = [cv2.cvtColor(cv2.resize(i, (48,48)), cv2.COLOR_GRAY2BGR) for i in X_test]\n",
        "X_train = np.concatenate([arr[np.newaxis] for arr in X_train])\n",
        "X_test = np.concatenate([arr[np.newaxis] for arr in X_test])\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 4us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 3s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z35UTg5c9_XZ",
        "colab_type": "code",
        "outputId": "7152d084-842f-4426-da98-b3c55566a3ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        }
      },
      "cell_type": "code",
      "source": [
        "conv_base = VGG16(weights=\"imagenet\", include_top=False, input_shape=(48,48,3))\n",
        "conv_base.trainable = False\n",
        "\n",
        "model = Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 4s 0us/step\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 1, 1, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 14,719,818\n",
            "Trainable params: 5,130\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zyKX9FWtAghc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        },
        "outputId": "6f2834b2-3882-4e79-b799-814aee4955c1"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_test, y_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 1779s 30ms/step - loss: 0.6111 - acc: 0.8054 - val_loss: 0.5533 - val_acc: 0.8112\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 1774s 30ms/step - loss: 0.5062 - acc: 0.8273 - val_loss: 0.4971 - val_acc: 0.8278\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 1776s 30ms/step - loss: 0.4634 - acc: 0.8402 - val_loss: 0.4680 - val_acc: 0.8359\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 1776s 30ms/step - loss: 0.4381 - acc: 0.8464 - val_loss: 0.4488 - val_acc: 0.8401\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 1779s 30ms/step - loss: 0.4208 - acc: 0.8515 - val_loss: 0.4344 - val_acc: 0.8472\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 1776s 30ms/step - loss: 0.4075 - acc: 0.8555 - val_loss: 0.4259 - val_acc: 0.8506\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 1777s 30ms/step - loss: 0.3976 - acc: 0.8588 - val_loss: 0.4208 - val_acc: 0.8535\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 1773s 30ms/step - loss: 0.3894 - acc: 0.8613 - val_loss: 0.4124 - val_acc: 0.8558\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 1781s 30ms/step - loss: 0.3823 - acc: 0.8644 - val_loss: 0.4076 - val_acc: 0.8571\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 1781s 30ms/step - loss: 0.3770 - acc: 0.8664 - val_loss: 0.4018 - val_acc: 0.8592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd3047de7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "g4Lj3Gn7Ag93",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        },
        "outputId": "033c7e3e-ac78-40fc-c4e1-490820bb65c9"
      },
      "cell_type": "code",
      "source": [
        "print(\"Train classification accuracy rate %0.05f\" % model.evaluate(X_train, y_train)[1])\n",
        "print(\"Test classification accuracy rate %0.05f\" % model.evaluate(X_test, y_test)[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 1531s 26ms/step\n",
            "Train classification accuracy rate 0.13635\n",
            "10000/10000 [==============================] - 259s 26ms/step\n",
            "Test classification accuracy rate 0.13940\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}